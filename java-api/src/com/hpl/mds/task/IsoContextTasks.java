/*
 *
 *  Managed Data Structures
 *  Copyright Â© 2016 Hewlett Packard Enterprise Development Company LP.
 *
 *  This program is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU Lesser General Public License as published by
 *  the Free Software Foundation, either version 3 of the License, or
 *  (at your option) any later version.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU Lesser General Public License for more details.
 *
 *  You should have received a copy of the GNU Lesser General Public License
 *  along with this program.  If not, see <http://www.gnu.org/licenses/>.
 *
 *  As an exception, the copyright holders of this Library grant you permission
 *  to (i) compile an Application with the Library, and (ii) distribute the 
 *  Application containing code generated by the Library and added to the 
 *  Application during this compilation process under terms of your choice, 
 *  provided you also meet the terms and conditions of the Application license.
 *
 */


package com.hpl.mds.task;

import java.util.Collections;
import java.util.HashSet;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import org.apache.log4j.Logger;

import com.hpl.mds.PubResult;
import com.hpl.mds.impl.ChangeBase;
import com.hpl.mds.impl.PubResultProxy;


public class IsoContextTasks {
	
	private static final Logger log = Logger.getLogger(IsoContextTasks.class);


	/** List<Task> tasks
	 *  tasks added to tasks list before their initial run
	 *  synchronizedList necessary where multiple threads running in same IsolationContext add tasks
	 *  List intended to capture some ordering of their execution (sufficiently correct?)
	 *  - assumption being that those tasks reexecuted in the same order will have correct results
	 */
	// tasks List replaced with concurrent tasks Set (ordering not used)
	// private List<com.hpl.mds.task.Task> tasks = Collections.synchronizedList(new ArrayList<Task>());
    private Set<Task> tasks = Collections.newSetFromMap(new ConcurrentHashMap<Task, Boolean>());
    
        // IsoContextTasks.currentTask replaced with multi-thread safe Task.currentTask
	// /** Task currentTask
	//  *  the current task being executed
	//  *  reads/writes executed in the current isolation context will be associated with the currentTask
	//  */
	// private Task currentTask;
	
//	/** List<Task> rerunTasks
//	 *  tasks added to rerunTasks list for rerunning to resolve conflicts on IC.publish
//	 *  - conflicted Tasks: reads/writes conflicted fields itself
//	 *  - dependent Tasks: dependent on a conflicted Task
//	 */
//	private List<Task> rerunTasks = Collections.synchronizedList(new ArrayList<Task>());
	
	/** TaskNode taskGraph
	 *  Graph capturing correct ordering of tasks to be rerun, taking account of all dependencies
	 *  - conflicted Tasks: reads/writes conflicted fields itself
	 *  - dependent Tasks: dependent on a conflicted Task  
	 */
	private TaskNode taskGraph;
	
	/** Map<> writeTasks // ex: changes
	 *  maps location to set of all tasks that have written this location
     *  also keeps track of the last task to write to this location
	 */
	// private Map<Long,Map<String,Set<Task>>> taskWrites = Collections.synchronizedMap(new HashMap<>());
	// private Map<Long,Map<String,WriteTaskContainer>> writeTasks = Collections.synchronizedMap(new HashMap<>());
	// private ConcurrentMap<Long,Map<String,WriteTaskContainer>> writeTasks = new ConcurrentHashMap<>();
	private ConcurrentMap<ChangeBase,WriteTaskContainer> writeTasks = new ConcurrentHashMap<>();

    /** Map<> readTasks
     * maps location to set of all tasks that have read this location
     */
	// private Map<Long,Map<String,TaskContainer>> readTasks = Collections.synchronizedMap(new HashMap<>());
	// private ConcurrentMap<Long,Map<String,TaskContainer>> readTasks = new ConcurrentHashMap<>();
	private ConcurrentMap<ChangeBase,TaskContainer> readTasks = new ConcurrentHashMap<>();

	/**
	 * taskConflicts
	 * - conflicts identified when IsolationContext.publish called, obtained from PubResult
	 * - the Java level representation of Core merge_result.conflicts
	 * - to be resolved by rerunning conflicted tasks
	 */
	// private Conflicts conflicts = null;
	private Set<ChangeBase> conflicts = null;
	
	/** add(Task)
	 * add the given task to the list of tasks (to be) run in the current IsolationContext
	 * @param task
	 */
	public void add(Task task) {
		tasks.add(task);
	}
	
        // IsoContextTasks.currentTask replaced with multi-thread safe Task.currentTask
	// public void setCurrentTask(Task task) {
	// 	currentTask = task;
	// }

	// public Task currentTask() {
	// 	return currentTask;
	// }
	
	
	public void addWrite(Task task, ChangeBase write) {
		log.debug("IsoContextTasks: addWrite: " + write);
		// log.debug("IsoContextTasks: addWrite: " + write + 
        //                   " hashcode: " + write.hashCode());
		WriteTaskContainer wtc = writeTasks.get(write);
		if (wtc == null) {
			wtc = new WriteTaskContainer(task);
			writeTasks.put(write, wtc);
		}
        else {
            wtc.addTask(task);
        }
		log.debug("IsoContextTasks: addWrite: added to tasks: " + wtc);
	}


	public void addRead(Task task, ChangeBase read) {
		log.debug("IsoContextTasks: addRead: " + read);
		// log.debug("IsoContextTasks: addRead: " + read + 
        //                   " hashcode: " + read.hashCode());
		TaskContainer tc = readTasks.get(read);
        if (tc == null) {
            tc = new TaskContainer(task);
	        readTasks.put(read, tc);
        }
        else {
            tc.addTask(task);
        }
	    log.debug("IsoContextTasks: addRead: added to tasks: " + tc);
	}
	
  
	public Task lastWriter(ChangeBase change) {
		log.debug("IsoContextTasks: lastWriter: " + change);
        WriteTaskContainer wtc = writeTasks.get(change);
        if (wtc != null) {
            return wtc.lastWriter();
        }
		return null;
	}
	
	public void rerunConflictedTasks(PubResult pubResult) {
		conflicts = ((PubResultProxy)pubResult).conflicts();
        identifyRerunTasks(conflicts);
        setRerunState();
        runRerunTasks();
	}
	
    /** 
     * identifyRerunTasks
     *
     * For each conflict, identify 
     * - tasks that read this conflicted location
     * then for each conflict, identify
     * - the task that was the lastWriter to this conflicted location
     * 
     * In identifying these conflicted tasks to rerun: 
     * - if a task read and wrote a conflicted location, 
     *   it will identified in first phase
     * - if a task only wrote a conflicted location, 
     *   the lastWriter will be identifed in the second phase
     *
     * For each conflicted rerun task
     * - add their dependent tasks
     * 
     */
	// private void identifyRerunTasks(Conflicts conflicts) {
	private void identifyRerunTasks(Set<ChangeBase> conflicts) {
 
        // Currently, task is rerun if it reads a conflicted location
        // and no differentiation is made between read and read-frozen.
        // 
        // However, conflicts should only include 
        //    Parent-write -> Child-read 
        // if reads are frozen on the child context
        // alt: if childContext.readsAreFrozen() then 
		
		// tmpTaskSet: 
		// add all "starter" tasks to tmpTaskSet first
		// then iterate through them to add tasks and their dependencies one-at-a-time to the taskGraph
		// Goal: tasks may appear multiple times in dependency lists, 
		// but ensure each task appears only once in taskGraph, 
		// at appropriate location to respect all dependencies.
		Set<Task> tmpTaskSet = new HashSet<>();

		// identify conflicted tasks - phase 1
        // - for each conflict, identify all tasks that read it 
		for (ChangeBase conflict : conflicts) {
			log.debug("identifyRerunTasks: conflict = " + conflict);
			TaskContainer tc = readTasks.get(conflict);
			if (tc != null) {
                Set<Task> tasks = tc.allTasks();
		        if (tasks != null) {
		        	tmpTaskSet.addAll(tasks);
		        }				
			}
			else {
				log.debug("identifyRerunTasks: no tasks for this conflict");
			}
		}
		

		// identify conflicted tasks - phase 2
        // - for each conflict, identify lastWriter to that location 
		for (ChangeBase conflict : conflicts) {
            Task lastWriter = lastWriter(conflict);
            if (lastWriter != null) {
                // taskGraph.addConflicted(lastWriter);
            	tmpTaskSet.add(lastWriter);
            }
        }

		// identify dependent tasks
		// - iterate through the tmpTaskSet of conflicted tasks, 
		//   adding each conflicted task and its dependencies, one-by-one to the taskGraph
		taskGraph = new TaskNode(); // ensuring taskGraph re-initialisation on every rerun
		TaskNode.addTasksAndDependencies(taskGraph, taskGraph, tmpTaskSet);
		log.debug("identifyRerunTasks: completed adding tasks and deps");
	}
	
    /** 
     * setRerunState
     * For all tasks to be rerun: 
     * - set all conflicted (read or write) locations to parent state
     * - set all rerun-task-written locations to parent state
     */
	private void setRerunState() {	
		log.debug("IsoContextTask.setRerunState: taskGraph.size: " + taskGraph.size());
		for (TaskIterator tasks = new TaskIterator(taskGraph); tasks.hasNext(); ) {
			Task task = tasks.nextBreadthFirst();
			log.debug("IsoContextTask.setRerunState: task: " + task.id());
			task.setRerunState();
		}
	}
	
	private void runRerunTasks() {
		log.debug("IsoContextTask.runRerunTasks: taskGraph.size: " + taskGraph.size());
		for (TaskIterator tasks = new TaskIterator(taskGraph); tasks.hasNext(); ) {
			Task task = tasks.nextBreadthFirst();
			log.debug("IsoContextTask.runRerunTasks: task: " + task.id());
			task.reRun();
		}
	}


} // end class IsoContextTasks
